{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d95b821c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from prefixspan import PrefixSpan\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report, log_loss\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from collections import Counter\n",
    "from IPython.display import display\n",
    "import ipywidgets as widgets\n",
    "import io\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4292dcb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======================================\n",
    "# Load & Preprocess\n",
    "# ======================================\n",
    "def load_and_preprocess_data(file_path):\n",
    "\n",
    "    df = pd.read_csv(file_path)\n",
    "    df['success_label'] = df['success_label'].astype(int)\n",
    "    df = df.drop_duplicates()\n",
    "\n",
    "    df = df.fillna({\n",
    "        'time_spent_minutes': df['time_spent_minutes'].median() if 'time_spent_minutes' in df.columns else 0,\n",
    "        'quiz_score': 0,\n",
    "        'assignment_score': 0,\n",
    "        'notes_taken': 0\n",
    "    })\n",
    "\n",
    "    df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
    "    df = df.sort_values(by=['student_id', 'timestamp'])\n",
    "\n",
    "    def create_activity(row):\n",
    "        activity = []\n",
    "        activity.append(\"video\" if row.get('video_watched_percent', 0) >= 70 else \"skip_video\")\n",
    "        activity.append(\"notes\" if row.get('notes_taken', 0) > 0 else \"no_notes\")\n",
    "        activity.append(\"quiz_pass\" if row.get('quiz_score', 0) >= 70 else \"quiz_fail\")\n",
    "        return \"_\".join(activity)\n",
    "\n",
    "    df['activity'] = df.apply(create_activity, axis=1)\n",
    "\n",
    "    sequences = (\n",
    "        df.groupby(['student_id', 'success_label'])['activity']\n",
    "        .apply(list)\n",
    "        .reset_index()\n",
    "    )\n",
    "\n",
    "    sequences['sequence_length'] = sequences['activity'].apply(len)\n",
    "\n",
    "    # ---- Outliers Handling (IQR) ----\n",
    "    Q1 = sequences['sequence_length'].quantile(0.25)\n",
    "    Q3 = sequences['sequence_length'].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    sequences['sequence_length'] = sequences['sequence_length'].clip(\n",
    "        Q1 - 1.5 * IQR,\n",
    "        Q3 + 1.5 * IQR\n",
    "    )\n",
    "\n",
    "    return df, sequences\n",
    "\n",
    "# ======================================\n",
    "# PrefixSpan\n",
    "# ======================================\n",
    "def run_prefixspan(sequences, min_support=5, top_k=5):\n",
    "\n",
    "    high_sequences = sequences[sequences['success_label'] == 1]['activity'].tolist()\n",
    "    low_sequences = sequences[sequences['success_label'] == 0]['activity'].tolist()\n",
    "\n",
    "    ps_high = PrefixSpan(high_sequences)\n",
    "    ps_low = PrefixSpan(low_sequences)\n",
    "\n",
    "    ps_high.minlen = 2\n",
    "    ps_low.minlen = 2\n",
    "\n",
    "    high_patterns = sorted(\n",
    "        ps_high.frequent(min_support),\n",
    "        key=lambda x: x[0],\n",
    "        reverse=True\n",
    "    )[:top_k]\n",
    "\n",
    "    low_patterns = sorted(\n",
    "        ps_low.frequent(min_support),\n",
    "        key=lambda x: x[0],\n",
    "        reverse=True\n",
    "    )[:top_k]\n",
    "\n",
    "    return high_patterns, low_patterns\n",
    "\n",
    "# ======================================\n",
    "# Simple GSP\n",
    "# ======================================\n",
    "def run_gsp(sequences, min_support=5):\n",
    "\n",
    "    def is_subsequence(sub, seq):\n",
    "        it = iter(seq)\n",
    "        return all(item in it for item in sub)\n",
    "\n",
    "    all_sequences = sequences['activity'].tolist()\n",
    "    items = set(item for seq in all_sequences for item in seq)\n",
    "\n",
    "    patterns = []\n",
    "\n",
    "    for item in items:\n",
    "        support = sum(is_subsequence([item], seq) for seq in all_sequences)\n",
    "        if support >= min_support:\n",
    "            patterns.append((support, [item]))\n",
    "\n",
    "    return sorted(patterns, reverse=True)\n",
    "\n",
    "# ======================================\n",
    "# Build ML Dataset\n",
    "# ======================================\n",
    "def build_ml_dataset(df, sequences):\n",
    "\n",
    "    features = sequences[['student_id', 'sequence_length']].copy()\n",
    "\n",
    "    if 'time_spent_minutes' in df.columns:\n",
    "        avg_time = (\n",
    "            df.groupby('student_id')['time_spent_minutes']\n",
    "            .mean()\n",
    "            .reset_index()\n",
    "            .rename(columns={'time_spent_minutes': 'avg_time_spent'})\n",
    "        )\n",
    "        features = features.merge(avg_time, on='student_id', how='left')\n",
    "\n",
    "    features = features.fillna(0)\n",
    "\n",
    "    X = features.drop(columns=['student_id'])\n",
    "    y = sequences['success_label']\n",
    "\n",
    "    return X, y\n",
    "\n",
    "# ======================================\n",
    "# Train & Evaluate\n",
    "# ======================================\n",
    "def train_and_evaluate_models(X, y):\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=42, stratify=y\n",
    "    )\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "\n",
    "    results = {}\n",
    "\n",
    "    param_grid = {\n",
    "        'n_estimators': [100, 200],\n",
    "        'max_depth': [None, 10]\n",
    "    }\n",
    "\n",
    "    grid = GridSearchCV(\n",
    "        RandomForestClassifier(random_state=42),\n",
    "        param_grid,\n",
    "        cv=3,\n",
    "        scoring='accuracy'\n",
    "    )\n",
    "    grid.fit(X_train, y_train)\n",
    "\n",
    "    best_rf = grid.best_estimator_\n",
    "\n",
    "    results['Random Forest'] = {\n",
    "        'accuracy': accuracy_score(y_test, best_rf.predict(X_test)),\n",
    "        'log_loss': log_loss(y_test, best_rf.predict_proba(X_test)),\n",
    "        'report_dict': classification_report(y_test, best_rf.predict(X_test), output_dict=True)\n",
    "    }\n",
    "\n",
    "    lr = LogisticRegression(max_iter=1000)\n",
    "    lr.fit(X_train, y_train)\n",
    "\n",
    "    results['Logistic Regression'] = {\n",
    "        'accuracy': accuracy_score(y_test, lr.predict(X_test)),\n",
    "        'log_loss': log_loss(y_test, lr.predict_proba(X_test)),\n",
    "        'report_dict': classification_report(y_test, lr.predict(X_test), output_dict=True)\n",
    "    }\n",
    "\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "38f029a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e1fcaf4d7764d2dbe82c805a34513ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FileUpload(value=(), accept='.csv', description='Upload')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "upload_widget = widgets.FileUpload(accept=\".csv\", multiple=False)\n",
    "display(upload_widget)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b10bd1fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "import io\n",
    "\n",
    "upload_widget = widgets.FileUpload(accept=\".csv\", multiple=False)\n",
    "process_button = widgets.Button(description=\"Load Dataset\")\n",
    "\n",
    "output = widgets.Output()\n",
    "\n",
    "def on_button_click(b):\n",
    "    with output:\n",
    "        output.clear_output()\n",
    "        if upload_widget.value:\n",
    "            file_name = list(upload_widget.value.keys())[0]\n",
    "            content = upload_widget.value[file_name]['content']\n",
    "            df, sequences = load_and_preprocess_data(io.BytesIO(content))\n",
    "            print(\"Dataset loaded successfully!\")\n",
    "            print(\"DataFrame shape:\", df.shape)\n",
    "            print(\"Sequences shape:\", sequences.shape)\n",
    "            \n",
    "            # تخزين البيانات للاستخدام في خلايا لاحقة\n",
    "            global loaded_df, loaded_sequences\n",
    "            loaded_df, loaded_sequences = df, sequences\n",
    "        else:\n",
    "            print(\"Please upload a CSV file.\")\n",
    "\n",
    "process_button.on_click(on_button_click)\n",
    "\n",
    "display(upload_widget, process_button, output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8273138",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ac864dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "high_patterns, low_patterns = run_prefixspan(sequences, min_support=5, top_k=5)\n",
    "gsp_patterns = run_gsp(sequences, min_support=5)\n",
    "\n",
    "print(\"Top patterns for high success students:\", high_patterns)\n",
    "print(\"Top patterns for low success students:\", low_patterns)\n",
    "print(\"GSP patterns:\", gsp_patterns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da2dc342",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = build_ml_dataset(df, sequences)\n",
    "print(\"ML dataset prepared!\")\n",
    "print(\"Features shape:\", X.shape)\n",
    "print(\"Labels shape:\", y.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3db6f1fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = train_and_evaluate_models(X, y)\n",
    "\n",
    "for model_name, metrics in results.items():\n",
    "    print(f\"\\n===== {model_name} =====\")\n",
    "    print(\"Accuracy:\", metrics['accuracy'])\n",
    "    print(\"Log Loss:\", metrics['log_loss'])\n",
    "    display(pd.DataFrame(metrics['report_dict']).transpose())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f1a0895",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution of sequence length\n",
    "plt.figure(figsize=(10,6))\n",
    "sns.histplot(data=sequences, x='sequence_length', hue='success_label', bins=20, kde=True, palette=['red','green'])\n",
    "plt.title(\"Distribution of Sequence Length by Success Label\")\n",
    "plt.xlabel(\"Sequence Length\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.legend(title='Success Label', labels=['Low Success','High Success'])\n",
    "plt.show()\n",
    "\n",
    "# Activity counts for high success\n",
    "high_sequences = sequences[sequences['success_label']==1]['activity'].tolist()\n",
    "high_flat = [item for seq in high_sequences for item in seq]\n",
    "high_counts = Counter(high_flat)\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "sns.barplot(x=list(high_counts.keys()), y=list(high_counts.values()), palette=\"Greens_d\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.title(\"Activity Counts for High Success Students\")\n",
    "plt.xlabel(\"Activity\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.show()\n",
    "\n",
    "# Activity counts for low success\n",
    "low_sequences = sequences[sequences['success_label']==0]['activity'].tolist()\n",
    "low_flat = [item for seq in low_sequences for item in seq]\n",
    "low_counts = Counter(low_flat)\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "sns.barplot(x=list(low_counts.keys()), y=list(low_counts.values()), palette=\"Reds_d\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.title(\"Activity Counts for Low Success Students\")\n",
    "plt.xlabel(\"Activity\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee7b4247",
   "metadata": {},
   "outputs": [],
   "source": [
    "# High success\n",
    "high_labels = [\"_\".join(p[1]) for p in high_patterns]\n",
    "high_support = [p[0] for p in high_patterns]\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "sns.barplot(x=high_labels, y=high_support, palette=\"Greens_d\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.title(\"Top PrefixSpan Patterns - High Success Students\")\n",
    "plt.ylabel(\"Support\")\n",
    "plt.show()\n",
    "\n",
    "# Low success\n",
    "low_labels = [\"_\".join(p[1]) for p in low_patterns]\n",
    "low_support = [p[0] for p in low_patterns]\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "sns.barplot(x=low_labels, y=low_support, palette=\"Reds_d\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.title(\"Top PrefixSpan Patterns - Low Success Students\")\n",
    "plt.ylabel(\"Support\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd3b4421",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flatten sequences\n",
    "plotly_data = []\n",
    "for idx, row in sequences.iterrows():\n",
    "    student_id = row['student_id']\n",
    "    for step, activity in enumerate(row['activity'], start=1):\n",
    "        plotly_data.append({\n",
    "            'student_id': student_id,\n",
    "            'step': step,\n",
    "            'activity': activity,\n",
    "            'success_label': row['success_label']\n",
    "        })\n",
    "\n",
    "plotly_df = pd.DataFrame(plotly_data)\n",
    "plotly_df['success_color'] = plotly_df['success_label'].map({1: 'High Success', 0: 'Low Success'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7eaf287",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.scatter(\n",
    "    plotly_df,\n",
    "    x='step',\n",
    "    y='student_id',\n",
    "    color='success_color',\n",
    "    symbol='activity',\n",
    "    hover_data=['student_id','activity','success_label'],\n",
    "    title=\"Interactive Student Activity Sequences by Success\",\n",
    "    color_discrete_map={'High Success':'green', 'Low Success':'red'},\n",
    "    height=600\n",
    ")\n",
    "fig.update_traces(marker=dict(size=12), selector=dict(mode='markers'))\n",
    "fig.update_layout(yaxis=dict(autorange=\"reversed\"))\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6c0554e",
   "metadata": {},
   "outputs": [],
   "source": [
    "heatmap_df = plotly_df.pivot_table(index='activity', columns='step', values='success_label', aggfunc='mean', fill_value=0)\n",
    "\n",
    "fig = px.imshow(\n",
    "    heatmap_df,\n",
    "    text_auto=True,\n",
    "    aspect=\"auto\",\n",
    "    color_continuous_scale=['red','green'],\n",
    "    labels=dict(x=\"Sequence Step\", y=\"Activity\", color=\"Success Rate\"),\n",
    "    title=\"Interactive Heatmap of Activity Success per Sequence Step\"\n",
    ")\n",
    "fig.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
